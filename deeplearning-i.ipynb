{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import requirements & Custom Dataset","metadata":{}},{"cell_type":"code","source":"import torch\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport numpy as np\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\nUSE_CUDA = torch.cuda.is_available()\nDEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\nprint(DEVICE)\n\nEPOCH = 25\n\ntransforms = transforms.Compose([\n    transforms.ToTensor(), \n    transforms.Normalize(mean=[0.485, 0.456, 0.486], std=[0.229, 0.224, 0.225])\n])\n\n# Class for load data from directory\nclass MyDataset(Dataset):\n    def __init__(self, image_dir, label, transforms=None, test=False):\n        self.image_dir = image_dir\n        self.label = label\n        self.image_list = os.listdir(self.image_dir)\n        self.transforms = transforms\n        self.test_mode = test\n    \n    def __len__(self):\n        return len(self.image_list)\n    \n    def __getitem__(self,idx):\n        image_name = os.path.join(self.image_dir, self.image_list[idx])\n        image = cv2.imread(image_name)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (224,224), cv2.INTER_AREA)\n        ###transform\n        image = transforms(image)\n       \n        if self.test_mode:\n            return (image, self.image_list[idx])\n        else:\n            return (image, self.label)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T07:24:11.306476Z","iopub.execute_input":"2021-06-02T07:24:11.306786Z","iopub.status.idle":"2021-06-02T07:24:11.318368Z","shell.execute_reply.started":"2021-06-02T07:24:11.306757Z","shell.execute_reply":"2021-06-02T07:24:11.317283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentation","metadata":{}},{"cell_type":"code","source":"from torchvision.transforms import Compose, ToTensor, ToPILImage\n\n# Class for load data from directory with augmentation by fliping images\nclass MyDataset_aug(Dataset):\n    def __init__(self, image_dir, label, transforms=None, test=False):\n        self.image_dir = image_dir\n        self.label = label\n        self.image_list = os.listdir(self.image_dir)\n        self.transforms = transforms\n        self.test_mode = test\n    \n    def __len__(self):\n        return len(self.image_list)\n    \n    def __getitem__(self,idx):\n        image_name = os.path.join(self.image_dir, self.image_list[idx])\n        image = cv2.imread(image_name)\n        flipLR_img = np.fliplr(image) # Flip original image\n        flipLR_img = cv2.cvtColor(flipLR_img, cv2.COLOR_BGR2RGB)\n        flipLR_img = cv2.resize(flipLR_img, (224,224), cv2.INTER_AREA)\n        ###transform\n        flipLR_img = transforms(flipLR_img)\n        \n        if self.test_mode:\n            return (flipLR_img, self.image_list[idx])\n        else:\n            return (flipLR_img, self.label)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T07:24:11.319853Z","iopub.execute_input":"2021-06-02T07:24:11.320409Z","iopub.status.idle":"2021-06-02T07:24:11.333556Z","shell.execute_reply.started":"2021-06-02T07:24:11.320362Z","shell.execute_reply":"2021-06-02T07:24:11.332726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ConcatDataset & DataLoader","metadata":{}},{"cell_type":"code","source":"balancing_train = MyDataset(\"../input/yoga6classes/balancing_train\", 0, transforms)\nbalancing_train_aug = MyDataset_aug(\"../input/yoga6classes/balancing_train\", 0, transforms)\n\ninverted_train = MyDataset(\"../input/yoga6classes/inverted_train\", 1, transforms)\ninverted_train_aug = MyDataset_aug(\"../input/yoga6classes/inverted_train\", 1, transforms)\n\nreclining_train = MyDataset(\"../input/yoga6classes/reclining_train\", 2, transforms)\nreclining_train_aug = MyDataset_aug(\"../input/yoga6classes/reclining_train\", 2, transforms)\n\nsitting_train = MyDataset(\"../input/yoga6classes/sitting_train\", 3, transforms)\nsitting_train_aug = MyDataset_aug(\"../input/yoga6classes/sitting_train\", 3, transforms)\n\nstanding_train = MyDataset(\"../input/yoga6classes/standing_train\", 4, transforms)\nstanding_train_aug = MyDataset_aug(\"../input/yoga6classes/standing_train\", 4, transforms)\n\nwheel_train = MyDataset(\"../input/yoga6classes/wheel_train\", 5, transforms)\nwheel_train_aug = MyDataset_aug(\"../input/yoga6classes/wheel_train\", 5, transforms)\n\n# Concat original images and augmented images\ntrain_set = ConcatDataset([balancing_train, inverted_train, reclining_train, sitting_train, standing_train, wheel_train,\n                          balancing_train_aug, inverted_train_aug, reclining_train_aug, sitting_train_aug, standing_train_aug, wheel_train_aug])\nprint(\"Number of Training set images : \", len(train_set))\n\nbalancing_valid = MyDataset(\"../input/yoga6classes/balancing_valid\", 0, transforms)\ninverted_valid = MyDataset(\"../input/yoga6classes/inverted_valid\", 1, transforms)\nreclining_valid = MyDataset(\"../input/yoga6classes/reclining_valid\", 2, transforms)\nsitting_valid = MyDataset(\"../input/yoga6classes/sitting_valid\", 3, transforms)\nstanding_valid = MyDataset(\"../input/yoga6classes/standing_valid\", 4, transforms)\nwheel_valid = MyDataset(\"../input/yoga6classes/wheel_valid\", 5, transforms)\nval_set = ConcatDataset([balancing_valid, inverted_valid, reclining_valid, sitting_valid, standing_valid, wheel_valid])\nprint(\"Number of Validation set images : \", len(val_set))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T07:24:11.335519Z","iopub.execute_input":"2021-06-02T07:24:11.335934Z","iopub.status.idle":"2021-06-02T07:24:11.370131Z","shell.execute_reply.started":"2021-06-02T07:24:11.335897Z","shell.execute_reply":"2021-06-02T07:24:11.369289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build model","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models\nfrom torch.optim import lr_scheduler\nimport torch.optim as optim\nimport torch.nn as nn\n\nmodel = models.resnet18(pretrained=True) # Using pretrained ResNet18\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 6) # Define fully connected layer\nmodel = model.to(DEVICE)\n\nprint(\"create model and optimizer\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T07:24:11.371485Z","iopub.execute_input":"2021-06-02T07:24:11.371745Z","iopub.status.idle":"2021-06-02T07:24:11.663185Z","shell.execute_reply.started":"2021-06-02T07:24:11.371715Z","shell.execute_reply":"2021-06-02T07:24:11.662406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train code & Loss function & test code & evaluation code","metadata":{}},{"cell_type":"code","source":"# Function for train model\ndef train(model, train_loader, optimizer, epoch):\n    model.train()\n    for i, (image, target) in enumerate(train_loader):\n        image, target = image.to(DEVICE), target.to(DEVICE)\n        output = model(image)\n \n        optimizer.zero_grad()\n        loss = F.cross_entropy(output, target).to(DEVICE)\n        loss.backward()\n        optimizer.step()     \n        if i % 10 == 0:\n            print('Train Epoch : {} [{}/{} ({:.0f})%]\\tLoss: {:.6f}'\n                 .format(epoch, i*len(image), len(train_loader.dataset), 100.*i / len(train_loader), loss.item()))\n\n# Function for validate model\ndef evaluate(model, val_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for(image, target) in val_loader:\n            image,target = image.to(DEVICE), target.to(DEVICE)\n            output = model(image)\n            \n            test_loss += F.cross_entropy(output, target, reduction = 'sum').item()\n            pred = output.max(1, keepdim = True)[1]\n            correct += pred.eq(target.view_as(pred)).sum().item()\n            \n    test_loss /= len(val_loader.dataset)\n    test_accuracy = 100. * correct / len(val_loader.dataset)\n    return test_loss, test_accuracy\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T07:24:11.664940Z","iopub.execute_input":"2021-06-02T07:24:11.665454Z","iopub.status.idle":"2021-06-02T07:24:11.675084Z","shell.execute_reply.started":"2021-06-02T07:24:11.665414Z","shell.execute_reply":"2021-06-02T07:24:11.674129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tuner","metadata":{}},{"cell_type":"code","source":"import random\nimport copy\nfrom itertools import product\n\n# Configuration set for tuner\nconfig = {\n    \"lr\": [0.001, 0.005, 0.0005],\n    \"batch_size\": [64, 32, 16, 8],\n    \"optimizer\": ['SGD','Adagrad', 'Adam']\n}\n\n# Epoch used for training in tuner\ntuning_epoch = 10 \n\n'''\nTuner to find out the best combination of hyper parameters and optimizer\nStrategy: Find the right combination with less epoch and train it back to that combination with more epoch\n'''\ndef tuner(model, train_data, test_data, config):\n    # Make all of combinations from configuration\n    combinations = list(product(config[\"lr\"], config[\"batch_size\"], config[\"optimizer\"]))\n   \n    best_combination = {\"combination\": [], \"acc\": 0.0}\n    best_loss = 1\n    best_epoch = 0\n    best_model = copy.deepcopy(model)\n    \n    for combi in combinations:\n        # Deep Copy original model to training to initialize weights at every combinations\n        compare_model = copy.deepcopy(model)\n        compare_model = compare_model.to(DEVICE)\n        \n        # Make Optimizer\n        if(combi[2] == 'SGD'):\n            optimizer = optim.SGD(compare_model.parameters(), lr=combi[0], momentum = 0.9, nesterov=True)\n        elif(combi[2] == 'Adagrad'):\n            optimizer = optim.Adagrad(compare_model.parameters(), lr=combi[0])\n        elif(combi[2] == 'Adam'):\n            optimizer = optim.Adam(compare_model.parameters(), lr=combi[0])\n        \n        # Make Loader\n        train_loader = DataLoader(train_data, batch_size=combi[1], shuffle=True)\n        val_loader = DataLoader(test_data, batch_size=combi[1], shuffle=False)\n        \n        # Training model with a combination\n        print('Training combination: ', combi, ' ...')\n        best = 0\n        for epoch in range(tuning_epoch):\n            train(compare_model, train_loader, optimizer, epoch)\n            test_loss, test_accuracy = evaluate(compare_model, val_loader)\n            if test_accuracy > best:\n                best = test_accuracy\n                best_loss = test_loss\n                best_epoch = epoch\n            print('[{}] Test Loss : {:.4f}, Accuracy : {:.4f}%'.format(epoch, test_loss, test_accuracy))\n    \n            # Stop epoch if it doesn't renew more than 5 epochs based on lowest loss\n            if epoch > best_epoch+5 and test_loss > best_loss:\n                break\n        \n        # Deciding best model\n        if best > best_combination[\"acc\"]:\n            best_combination[\"acc\"] = best\n            best_combination[\"combination\"] = combi\n            best_model = compare_model\n            \n        print('---------------------------------------------------------')\n        print(\"finish train a combination\")\n        print(\"current best acc: \", best_combination[\"acc\"], \"with combination: \", \"lr: {}, batch_size: {}, optimizer: {}\".format(best_combination[\"combination\"][0], best_combination[\"combination\"][1], best_combination[\"combination\"][2]))\n    \n                    \n    model = best_model\n    torch.save(model.state_dict(), \"./best_model.pth\")\n    return best_combination[\"combination\"]\n    \n# Get the best combination of hyper paramers and optimizer\ncombi = tuner(model, train_set, val_set, config)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T07:24:11.678106Z","iopub.execute_input":"2021-06-02T07:24:11.678353Z","iopub.status.idle":"2021-06-02T07:24:34.496004Z","shell.execute_reply.started":"2021-06-02T07:24:11.678329Z","shell.execute_reply":"2021-06-02T07:24:34.493255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main code & Save the best model","metadata":{}},{"cell_type":"code","source":"import time\nstart = time.time()\nbest = 0\n\n# Decide optimizer to use\nif(combi[2] == 'SGD'):\n    optimizer = optim.SGD(model.parameters(), lr=combi[0], momentum = 0.9, nesterov=True)\n\nif(combi[2] == 'Adagrad'):\n    optimizer = optim.Adagrad(model.parameters(), lr=combi[0])\n    \nif(combi[2] == 'Adam'):\n    optimizer = optim.Adam(model.parameters(), lr=combi[0])\n\nBATCH_SIZE = combi[1]\n\n# Make loaders\ntrain_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)\n\n# Train\nfor epoch in range(EPOCH):\n    train(model, train_loader, optimizer, epoch)\n    test_loss, test_accuracy = evaluate(model, val_loader)\n    if test_accuracy > best:\n        best = test_accuracy\n        torch.save(model.state_dict(), \"./best_model.pth\")\n    print('[{}] Test Loss : {:.4f}, Accuracy : {:.4f}%'.format(epoch, test_loss, test_accuracy))\n\nend = time.time()\ntime = end - start\n\n# Print results\nprint(\"finish train\")\nprint(\"best acc: \", best)\nprint(\"time: {}h, {}m,{}s\".format(int(time/3600), int(time/60), time%60))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T07:24:34.496735Z","iopub.status.idle":"2021-06-02T07:24:34.497220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Save the predicted value as a CSV file","metadata":{}},{"cell_type":"code","source":"import csv\n\nload = torch.load('./best_model.pth')\nmodel.load_state_dict(load) # load weights from the best model\nmodel.eval()\nprint(\"load model for test set\")\n\nf = open(\"./prediction.csv\", \"w\", newline=\"\") # open file to save prediction results\nw = csv.writer(f)\nw.writerow(['id', 'target'])\n\n# Make test data loader\ntest_set = MyDataset(\"../input/yogatestdataset\", 0,transforms, test = True)\ntest_loader = DataLoader(test_set, batch_size=combi[1], shuffle=False)\n\npreds = []\nimg_ids = []\ncorrect = 0\n\n# Predict class with test data\nwith torch.no_grad():\n    for (image, image_name) in test_loader:\n        image = image.to(DEVICE)\n        output = model(image)\n        \n        pred = output.max(1, keepdim = True)[1]\n        preds.extend(pred)\n        img_ids.extend(image_name)\n        \n# Write results to .csv\nfor i in range(600):\n    w.writerow([img_ids[i][:-4], str(preds[i].item())])\n    \nf.close()\nprint(\"save prediction csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T07:24:34.498266Z","iopub.status.idle":"2021-06-02T07:24:34.498945Z"},"trusted":true},"execution_count":null,"outputs":[]}]}